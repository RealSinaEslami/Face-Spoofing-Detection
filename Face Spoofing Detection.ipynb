{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad0fd661",
   "metadata": {},
   "source": [
    "# 1.Capture datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47649e78",
   "metadata": {},
   "source": [
    "### 1.1 Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import uuid\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac357a7",
   "metadata": {},
   "source": [
    "### 1.2 Make directory pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'dataset'\n",
    "train_dataset_dir = 'dataset\\\\train'\n",
    "test_dataset_dir = 'dataset\\\\test'\n",
    "# --------------------------------- #\n",
    "train_dir = 'data\\\\train'\n",
    "test_dir = 'data\\\\test'\n",
    "# --------------------- #\n",
    "real_test_dir = 'data\\\\test\\\\real'\n",
    "real_train_dir = 'data\\\\train\\\\real'\n",
    "# --------------------------------- #\n",
    "spoof_test_dir = 'data\\\\test\\\\spoof'\n",
    "spoof_train_dir = 'data\\\\train\\\\spoof'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7da272e",
   "metadata": {},
   "source": [
    "### 1.3 Capture images for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed42885",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv.VideoCapture(0)\n",
    "path = os.path.join('dataset')\n",
    "\n",
    "for imgnum in range(20):\n",
    "    print(f'Capturing image: {imgnum}')\n",
    "    \n",
    "    ret, frame = cam.read()\n",
    "    img_path = os.path.join(path, f'{str(uuid.uuid1())}.jpg')\n",
    "    cv.imwrite(img_path, frame)\n",
    "    cv.imshow('Camera', frame)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48315d",
   "metadata": {},
   "source": [
    "### 1.4 Count images in existing folders with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bffb387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train folder count\n",
    "train_path = os.path.join('data', 'train')\n",
    "RTPath = os.path.join('data', 'train', 'real')\n",
    "STPath = os.path.join('data', 'train', 'spoof')\n",
    "RTLength = os.listdir(RTPath)\n",
    "STLength = os.listdir(STPath)\n",
    "\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(train_path)\n",
    "train_iterator = train_data.as_numpy_iterator()\n",
    "train_batch = train_iterator.next()\n",
    "\n",
    "images = len(RTLength) + len(STLength)\n",
    "print(f\"{images} images has been found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_batch = int(images / 20)\n",
    "print(f\"Batch size for train part: {tr_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c4b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test folder count\n",
    "test_path = os.path.join('data', 'test')\n",
    "RTPath = os.path.join('data', 'test', 'real')\n",
    "STPath = os.path.join('data', 'test', 'spoof')\n",
    "RTLength = os.listdir(RTPath)\n",
    "STLength = os.listdir(STPath)\n",
    "\n",
    "test_data = tf.keras.utils.image_dataset_from_directory(test_path)\n",
    "test_iterator = test_data.as_numpy_iterator()\n",
    "test_batch = test_iterator.next()\n",
    "\n",
    "images = len(RTLength) + len(STLength)\n",
    "print(f\"{images} images has been found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baab31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_batch = int(images / 20)\n",
    "print(f\"Batch size for test part: {te_batch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7541f741",
   "metadata": {},
   "source": [
    "### 1.5 Scale the images to make them an array with numbers between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff6a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scale = train_data.map(lambda x,y: (x/255, y))\n",
    "train_scaled_iterator = train_scale.as_numpy_iterator().next()[0]\n",
    "\n",
    "maximum = train_scale.as_numpy_iterator().next()[0].max()\n",
    "minimum = train_scale.as_numpy_iterator().next()[0].min()\n",
    "\n",
    "print(f\"Maximum value in train map: {maximum}\")\n",
    "print(f\"Minimum value in train map: {minimum}\")\n",
    "\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "test_scale = test_data.map(lambda x,y: (x/255, y))\n",
    "test_scaled_iterator = test_scale.as_numpy_iterator().next()[0]\n",
    "\n",
    "maximum = test_scale.as_numpy_iterator().next()[0].max()\n",
    "minimum = test_scale.as_numpy_iterator().next()[0].min()\n",
    "\n",
    "print(f\"Maximum value in test map: {maximum}\")\n",
    "print(f\"Minimum value in test map: {minimum}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ac5199",
   "metadata": {},
   "source": [
    "# 2.Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a1b8d9",
   "metadata": {},
   "source": [
    "### 2.1 Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d80521",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['real', 'spoof']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a23c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(file, NumberOfImages):\n",
    "    img_path = []\n",
    "    for types in folders:\n",
    "        \n",
    "        path = os.path.join(file, types)\n",
    "        # E.X-1: path = os.path.join('train', 'real')\n",
    "        \n",
    "        counter = 1\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            if counter > NumberOfImages:\n",
    "                break\n",
    "            else:\n",
    "                img_path.append(os.path.join(path, img))\n",
    "                # E.X-2: img_path (which is a list) will become appended in path of E.X-1 and path of image\n",
    "                \n",
    "                counter = counter + 1\n",
    "    \n",
    "    return img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3da454",
   "metadata": {},
   "outputs": [],
   "source": [
    "choosen_images = get_images(file = train_dir, NumberOfImages = 25)\n",
    "print(f'Number of choosen images for visualize: \"{len(choosen_images)}\"')\n",
    "print('\\n')\n",
    "print(choosen_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset(img_path, rows, cols):\n",
    "    fig = plt.figure(figsize = (17,17))\n",
    "    \n",
    "    for i in range(1, (rows*cols)+1):\n",
    "        fig.add_subplot(rows, cols, i)\n",
    "        img = cv.imread(img_path[i])\n",
    "        \n",
    "        plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "        plt.xlabel(img_path[i].split('\\\\')[2])\n",
    "        # E.X-3: plt.xlabel and .split command will give us a feedback about our image that it's in 'real' or 'spoof' folder \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1511e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(img_path = choosen_images, rows = 4, cols = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5eeece",
   "metadata": {},
   "source": [
    "# 3.Model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282d1b53",
   "metadata": {},
   "source": [
    "### 3.1 Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45543ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Input, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.models import model_from_json\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa59de",
   "metadata": {},
   "source": [
    "### 3.2 Different contrast and Rotation of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39304686",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(brightness_range=(0.8,1.2),\n",
    "                                   rotation_range=30,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   fill_mode='nearest',\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.3,\n",
    "                                   rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04708b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5a71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(160,160),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='binary',\n",
    "                                                    batch_size=tr_batch,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca17f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=(160,160),\n",
    "                                                  color_mode='rgb',\n",
    "                                                  class_mode='binary',\n",
    "                                                  batch_size=te_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f301b64c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MobileNetV2 is a convolutional neural network architecture that seeks to perform well on mobile devices\n",
    "\n",
    "mobilenet = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(160,160,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b534ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we are using images (not documents like PDF), we have to turn the mobilenet.trainable off\n",
    "mobilenet.trainable = False\n",
    "\n",
    "output = Flatten()(mobilenet.output)\n",
    "output = Dropout(0.3)(output)\n",
    "output = Dense(units = 8, activation='relu')(output)\n",
    "prediction = Dense(1, activation='sigmoid')(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0d720c",
   "metadata": {},
   "source": [
    "### 3.3 Check the layers of  the model with MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c00ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = mobilenet.input, outputs = prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9602615",
   "metadata": {},
   "source": [
    "### 3.4 Compile the model with Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1bcfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(\n",
    "    learning_rate=0.000001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feff945",
   "metadata": {},
   "source": [
    "### 3.5 Creating a directory for \"Model Checkpoint\" which doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5dc781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir('data\\\\model_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f9416",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('data\\\\model_checkpoint\\\\Checkpoint model_{epoch:02d}-{val_accuracy:.6f}.h5',\n",
    "                                   monitor='val_loss', mode='min', verbose=1, save_best_only=True, save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38255cb4",
   "metadata": {},
   "source": [
    "# 4.Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230223b9",
   "metadata": {},
   "source": [
    "### 4.1 Train data to become more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9221bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5611b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // 7,\n",
    "    validation_data = test_generator, \n",
    "    validation_steps = test_generator.samples // 2,\n",
    "    epochs = epoch,\n",
    "    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902acc5e",
   "metadata": {},
   "source": [
    "### 4.2 Ploting the accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bbf3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"finall_model_mobilenet.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e10323e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_accuracy = history.history['accuracy']\n",
    "validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(0, epoch)\n",
    "\n",
    "plt.plot(epochs,train_accuracy, color='green', label='Training Accuracy')\n",
    "plt.plot(epochs,validation_accuracy, color='blue', label='Validation Accuracy')\n",
    "\n",
    "plt.title('Training & Validation Accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54aefb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(0, epoch)\n",
    "\n",
    "plt.plot(epochs, train_loss, color='red', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, color='orange', label='validation Loss')\n",
    "\n",
    "plt.title('Training & Validation Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7090779",
   "metadata": {},
   "source": [
    "# 5.Real Time face spoofing recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a81d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "\n",
    "# Load Face Detection Model\n",
    "face_cascade = cv.CascadeClassifier(\"models\\\\haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Load Anti-Spoofing Model graph\n",
    "json_file = open('results.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load antispoofing model weights\n",
    "model.load_weights('models\\\\anti_spoofing_models\\\\antispoofing_model.h5')\n",
    "print(\"Model loaded from directory\")\n",
    "\n",
    "video = cv.VideoCapture(0)\n",
    "while video.isOpened():\n",
    "    try:\n",
    "        ret, frame = video.read()\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:  \n",
    "            face = frame[y-5:y+h+5, x-5:x+w+5]\n",
    "            resized_face = cv.resize(face,(160,160))\n",
    "            resized_face = resized_face.astype(\"float\") / 255.0\n",
    "            \n",
    "            # resized_face = img_to_array(resized_face)\n",
    "            resized_face = np.expand_dims(resized_face, axis=0)\n",
    "            # pass the face ROI through the trained liveness detector\n",
    "            \n",
    "            # model to determine if the face is \"real\" or \"fake\"\n",
    "            preds = model.predict(resized_face)[0]\n",
    "            print(preds)\n",
    "            if preds > 0.5:\n",
    "                label = 'spoof'\n",
    "                cv.putText(frame, label, (x,y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
    "                cv.rectangle(frame, (x, y), (x+w,y+h),(0, 0, 255), 2)\n",
    "            \n",
    "            else:\n",
    "                label = 'real'\n",
    "                cv.putText(frame, label, (x,y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "                cv.rectangle(frame, (x, y), (x+w,y+h),(0, 255, 0), 2)\n",
    "        \n",
    "        cv.imshow('Camera', frame)\n",
    "        \n",
    "        key = cv.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "video.release()        \n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
